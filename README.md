# Video Question Answering Review(Video QA)

## 2021

### BMVC

| Paper                                                        | Code         |
| :----------------------------------------------------------- | ------------ |
| [Transferring Domain-Agnostic Knowledge in Video Question Answering](https://www.bmvc2021-virtualconference.com/assets/papers/1187.pdf) - Tianran Wu et al, **BMVC 2021**. | **No Code ** |

### ACM MM

| Paper                                                        | Code        |
| :----------------------------------------------------------- | ----------- |
| [Progressive Graph Attention Network for Video Question Answering](https://dl.acm.org/doi/pdf/10.1145/3474085.3475193?casa_token=_Grng46wZGYAAAAA:o9h9MIcJZ-OlnN55nTNIOXBd9BmizvwzgMQx7tOEQyf2fFpOM-KKUdFwtI_V0KF9fzS7_gwUemrKuQ) - Liang Peng et al, **ACM MM 2021**. | **No Code** |
| [Pairwise VLAD Interaction Network for Video Question Answering](https://dl.acm.org/doi/pdf/10.1145/3474085.3475620?casa_token=DAebTWgAScEAAAAA:uVos17zw3qKYqXd_83WbFL5TjuzAzCMic54Zg9fI66UJ1P5E-kO8OG_QmwMQkuLacDaSCRe2v2_q4Q) - Hui Wang et al, **ACM MM 2021.** | **No Code** |

### CVPR

| Paper                                                        | Code                                               |
| ------------------------------------------------------------ | -------------------------------------------------- |
| [SUTD-TrafficQA: A Question Answering Benchmark and an Efficient Network for Video Reasoning Over Traffic Events](https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_SUTD-TrafficQA_A_Question_Answering_Benchmark_and_an_Efficient_Network_for_CVPR_2021_paper.pdf) - Li Xu et al, **CVPR 2021**. | [[code]](https://github.com/SUTDCV/SUTD-TrafficQA) |
| [Bridge To Answer: Structure-Aware Graph Interaction Network for Video Question Answering](https://openaccess.thecvf.com/content/CVPR2021/papers/Park_Bridge_To_Answer_Structure-Aware_Graph_Interaction_Network_for_Video_Question_CVPR_2021_paper.pdf) - Jungin Park et al, **CVPR 2021**. | **No Code**                                        |
| [NExT-QA: Next Phase of Question-Answering to Explaining Temporal Actions](https://openaccess.thecvf.com/content/CVPR2021/papers/Xiao_NExT-QA_Next_Phase_of_Question-Answering_to_Explaining_Temporal_Actions_CVPR_2021_paper.pdf) - Junbin Xiao et al, **CVPR 2021**. | [[code]](https://github.com/doc-doc/NExT-QA)       |

### ICCV

| Paper                                                        | Code                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [Just Ask: Learning To Answer Questions From Millions of Narrated Videos](https://openaccess.thecvf.com/content/ICCV2021/html/Yang_Just_Ask_Learning_To_Answer_Questions_From_Millions_of_Narrated_ICCV_2021_paper.html) - Antoine Yang et al, **ICCV 2021**. | [[code]](https://github.com/antoyang/just-ask)               |
| [Env-QA: A Video Question Answering Benchmark for Comprehensive Understanding of Dynamic Environments](https://openaccess.thecvf.com/content/ICCV2021/html/Gao_Env-QA_A_Video_Question_Answering_Benchmark_for_Comprehensive_Understanding_of_ICCV_2021_paper.html) - Difei Gao et al, **ICCV 2021**. | **No Code**                                                  |
| [On The Hidden Treasure of Dialog in Video Question Answering](https://openaccess.thecvf.com/content/ICCV2021/html/Engin_On_the_Hidden_Treasure_of_Dialog_in_Video_Question_Answering_ICCV_2021_paper.html) - Deniz Engin et al, **ICCV 2021.** | [[code]](https://github.com/InterDigitalInc/DialogSummary-VideoQA) |
| [Pano-AVQA: Grounded Audio-Visual Question Answering on 360deg Videos](https://openaccess.thecvf.com/content/ICCV2021/html/Yun_Pano-AVQA_Grounded_Audio-Visual_Question_Answering_on_360deg_Videos_ICCV_2021_paper.html) - Heeseung Yun et al, **ICCV 2021**. | [[code]](https://github.com/hs-yn/panoavqa)                  |
| [HAIR: Hierarchical Visual-Semantic Relational Reasoning for Video Question Answering](https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_HAIR_Hierarchical_Visual-Semantic_Relational_Reasoning_for_Video_Question_Answering_ICCV_2021_paper.pdf) - Fei Liu et al, **ICCV** **2021**. | **No Code**                                                  |
| [Video Question Answering Using Language-Guided Deep Compressed-Domain Video Feature](https://openaccess.thecvf.com/content/ICCV2021/papers/Kim_Video_Question_Answering_Using_Language-Guided_Deep_Compressed-Domain_Video_Feature_ICCV_2021_paper.pdf) - Nayoung Kim et al, **ICCV 2021.** | **No Code**                                                  |

### NeurIPS

| Paper                                                        | Code        |
| ------------------------------------------------------------ | ----------- |
| [Learning from Inside: Self-driven Siamese Sampling and Reasoning for Video Question Answering](https://openreview.net/pdf?id=lDVeaQIScg) Weijiang Yu et al, **NeurIPS 2021.** | **No Code** |

### NAACL-HLT

| Paper                                                        | Code        |
| ------------------------------------------------------------ | ----------- |
| [Video Question Answering with Phrases via Semantic Roles](https://arxiv.org/abs/2104.03762) - Arka Sadhu et al, **NAACL-HLT 2021**. | **No Code** |

### EMNLP

| Paper                                                        | Code                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding](https://arxiv.org/pdf/2109.14084v2.pdf) - Hu Xu et al, **EMNLP 2021.** | [[code]](https://github.com/pytorch/fairseq/blob/main/examples/MMPT/README.md) |

### **ACL**

| Paper                                                        | Code                                                 |
| ------------------------------------------------------------ | ---------------------------------------------------- |
| [Attend What You Need: Motion-Appearance Synergistic Networks for Video Question Answering](https://aclanthology.org/2021.acl-long.481.pdf) - Ahjeong Seo et al, **ACL 2021**. | [[code]](https://github.com/ahjeongseo/MASN-pytorch) |
| [Multi-Scale Progressive Attention Network for Video Question Answering](https://aclanthology.org/2021.acl-short.122.pdf) Zhicheng Guo et al, **ACL 2021.** | **No code**                                          |

### AAAI

| Paper                                                        | Code        |
| ------------------------------------------------------------ | ----------- |
| [Self-supervised Pre-training and Contrastive Representation Learning for Multiple-choice Video QA](https://arxiv.org/pdf/2009.08043.pdf) - Seonhoon Kim et al, **AAAI 2021.** | **No code** |



## 2020

### BMVC

| Paper                                                        | Code        |
| ------------------------------------------------------------ | ----------- |
| [Two-Stream Spatiotemporal Compositional Attention Network for VideoQA](https://www.bmvc2020-conference.com/assets/papers/0877.pdf) - Taiki Miyanishi et al, **BMVC 2020** | **No code** |
| [On Modality Bias in the TVQA Dataset](https://www.bmvc2020-conference.com/assets/papers/0476.pdf) - Thomas Winterbottom et al, **BMVC 2020** | **No code** |

### ACM MM

| Paper                                                        | Code        |
| :----------------------------------------------------------- | ----------- |
| [Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering](https://dl.acm.org/doi/pdf/10.1145/3394171.3413649?casa_token=t_FdzbDWMTwAAAAA:MOauUpjWtd_TXGe2kwsxR67UG5yTy3nhCVdjeG2mWH2pw8iE9CZFRCDgDGcZ62HiiJ8JTCrEliV6Kg) - Fei Liu et al, **ACM MM 2020**. | **No code** |

### ECCV

| Paper                                                        | Code                                                         |
| :----------------------------------------------------------- | ------------------------------------------------------------ |
| [Knowledge-Based Video Question Answering with Unsupervised Scene Descriptions](http://www.ecva.net/papers/eccv_2020/papers_ECCV/html/3056_ECCV_2020_paper.php) - Noa Garcia et al, **ECCV 2020.** | [[code]](https://github.com/InterDigitalInc/DialogSummary-VideoQA) |

### CVPR

| Paper                                                        | Code                                                |
| :----------------------------------------------------------- | --------------------------------------------------- |
| [Hierarchical Conditional Relation Networks for Video Question Answering](http://openaccess.thecvf.com/content_CVPR_2020/html/Le_Hierarchical_Conditional_Relation_Networks_for_Video_Question_Answering_CVPR_2020_paper.html) - Thao Minh Le et al, **CVPR 2020.** | [[code]](https://github.com/thaolmk54/hcrn-videoqa) |
| [Modality Shifting Attention Network for Multi-Modal Video Question Answering](http://openaccess.thecvf.com/content_CVPR_2020/html/Kim_Modality_Shifting_Attention_Network_for_Multi-Modal_Video_Question_Answering_CVPR_2020_paper.html) - Junyeong Kim et al, **CVPR 2020.** | **No code**                                         |

### ACL

| Paper                                                        | Code                                                         |
| :----------------------------------------------------------- | ------------------------------------------------------------ |
| [Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA](https://arxiv.org/abs/2005.06409) - Hyounghun Kim et al, **ACL 2020**. | [[code]](https://github.com/hyounghk/VideoQADenseCapFrameGate-ACL2020) |
| [TVQA+: Spatio-Temporal Grounding for Video Question Answering](https://arxiv.org/abs/1904.11574) - Jie Lei et al, **ACL 2020.** | [[code]](https://github.com/jayleicn/TVQAplus)               |

### WACV

| Paper                                                        | Code                                                         |
| :----------------------------------------------------------- | ------------------------------------------------------------ |
| [BERT representations for Video Question Answering](http://openaccess.thecvf.com/content_WACV_2020/papers/Yang_BERT_representations_for_Video_Question_Answering_WACV_2020_paper.pdf) - Zekun Yang et al, **WACV 2020.** | [[code]](https://github.com/Jumperkables/tvqa_modality_bias) |

### AAAI

| Paper                                                        | Code        |
| ------------------------------------------------------------ | ----------- |
| [Divide and Conquer: Question­‐Guided Spatio­‐Temporal Contextual Attention for Video Question Answering](https://github.com/jokieleung/awesome-visual-question-answering/blob/master) - Jianwen Jiang et al, **AAAI 2020.** | **No code** |
| [Reasoning with Heterogeneous Graph Alignment for Video Question Answering](https://github.com/jokieleung/awesome-visual-question-answering/blob/master) - Pin Jiang et al, **AAAI 2020.** | **No code** |
| [Location­‐aware Graph Convolutional Networks for Video Question Answering](https://github.com/jokieleung/awesome-visual-question-answering/blob/master) - Deng Huang et al, **AAAI 2020**. | **No code** |
| [KnowIT VQA: Answering Knowledge­‐Based Questions about Videos](https://github.com/jokieleung/awesome-visual-question-answering/blob/master) - Noa Garcia et al, **AAAI 2020**. | **No code** |



## 2019

### BMVC

| Paper                                                        | Code                                       |
| ------------------------------------------------------------ | ------------------------------------------ |
| [Spatio-temporal Relational Reasoning for Video Question Answering](https://open.library.ubc.ca/media/stream/pdf/24/1.0384578/3) - Gursimran Singh et al, **BMVC 2019**. | [[code]](https://github.com/SunDoge/L-GCN) |

### ACM MM

| Paper                                                        | Code        |
| :----------------------------------------------------------- | ----------- |
| [Multi-interaction Network with Object Relation for Video Question Answering](https://dl.acm.org/doi/pdf/10.1145/3343031.3351065?casa_token=C9mRxFAPp6gAAAAA:tJssAXVOlNxirsVBMT8kn3kH82wzstCevc8HKYssu5CZRK15Exp5U_YO1SsMvDMsV9lRgu4CpwnwpA) - Weike Jin et al, **ACM MM 2019**. | **No code** |
| [Question-Aware Tube-Switch Network for Video Question Answering](https://dl.acm.org/doi/pdf/10.1145/3343031.3350969?casa_token=Pb1ONefcA_4AAAAA:aJCds85eE4Yj8PmFkBo_xt0GmXX4OGLycjkYmC1JWTA61fOG6rAvYVLC4Rz-CzB_cXh2vKlpPCGubg) - Tianhao Yang et al, **ACM MM 2019.** | **No code** |
| [Learnable Aggregating Net with Diversity Learning for Video Question Answering](https://dl.acm.org/doi/pdf/10.1145/3343031.3350971) - Xiangpeng Li et al, **ACM MM 2019.** | **No code** |

### CVPR

| Paper                                                        | Code                                                         |
| :----------------------------------------------------------- | ------------------------------------------------------------ |
| [Video Relationship Reasoning using Gated Spatio-Temporal Energy Graph](https://arxiv.org/abs/1903.10547) - Yao-Hung Hubert Tsai et al, **CVPR 2019.** | [[code\]](https://github.com/yaohungt/Gated-Spatio-Temporal-Energy-Graph) |
| [Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering](https://openaccess.thecvf.com/content_CVPR_2019/papers/Fan_Heterogeneous_Memory_Enhanced_Multimodal_Attention_Model_for_Video_Question_Answering_CVPR_2019_paper.pdf) - Chenyou Fan et al, **CVPR 2019**. | [[code]](https://github.com/fanchenyou/HME-VideoQA)          |
| [Progressive Attention Memory Network for Movie Story Question Answering](https://openaccess.thecvf.com/content_CVPR_2019/papers/Kim_Progressive_Attention_Memory_Network_for_Movie_Story_Question_Answering_CVPR_2019_paper.pdf) - Junyeong Kim et al, **CVPR 2019**. | **No code**                                                  |

### AAAI



| Paper                                                        | Code                                             |
| ------------------------------------------------------------ | ------------------------------------------------ |
| [Structured Two-stream Attention Network for Video Question Answering](https://ojs.aaai.org//index.php/AAAI/article/view/4602) - Lianli Gao et al, **AAAI 2019**. | **No code**                                      |
| [Beyond RNNs: Positional Self-Attention with Co-Attention for Video Question Answering](https://www.semanticscholar.org/paper/Beyond-RNNs%3A-Positional-Self-Attention-with-for-Li-Song/565359aac8914505e6b02db05822ee63d3ffd03a) - Xiangpeng Li et al, **AAAI 2019**. | [[code\]](https://github.com/lixiangpengcs/PSAC) |

## 2018

### ACM MM

| Paper                                                        | Code                                                         |
| :----------------------------------------------------------- | ------------------------------------------------------------ |
| [Explore Multi-Step Reasoning in Video Question Answering](https://doi.org/10.1145/3240508.3240563) - Xiaomeng Song et al, **ACM MM 2018**. | [[code\]](https://github.com/SVQA-founder/SVQA/tree/master/code) [[SVQA dataset\]](https://svqa-founder.github.io/SVQA/) |

### ECCV

| Paper                                                        | Code                                                |
| ------------------------------------------------------------ | --------------------------------------------------- |
| [Multimodal Dual Attention Memory for Video Story Question Answering](http://openaccess.thecvf.com/content_ECCV_2018/html/Kyungmin_Kim_Multimodal_Dual_Attention_ECCV_2018_paper.html) - Kyung-Min Kim et al, **ECCV 2018**. | **No code**                                         |
| [A Joint Sequence Fusion Model for Video Question Answering and Retrieval](http://openaccess.thecvf.com/content_ECCV_2018/html/Youngjae_Yu_A_Joint_Sequence_ECCV_2018_paper.html) - Youngjae Yu et al, **ECCV 2018**. | [[code]](https://github.com/antoine77340/howto100m) |

### IJCAI

| Paper                                                        | Code        |
| ------------------------------------------------------------ | ----------- |
| [Multi-Turn Video Question Answering via Multi-Stream Hierarchical Attention Context Network](https://www.ijcai.org/proceedings/2018/513) - Zhou Zhao et al, **IJCAI 2018**. | **No code** |
| [Open-Ended Long-form Video Question Answering via Adaptive Hierarchical Reinforced Networks](https://www.ijcai.org/proceedings/2018/512) - Zhou Zhao et al, **IJCAI 2018**. | **No code** |

### CVPR

| Paper                                                        | Code        |
| :----------------------------------------------------------- | ----------- |
| [Motion-Appearance Co-Memory Networks for Video Question Answering](http://openaccess.thecvf.com/content_cvpr_2018/html/Gao_Motion-Appearance_Co-Memory_Networks_CVPR_2018_paper.html) - Jiyang Gao et al, **CVPR 2018**. | **No code** |

### AAAI

| Paper                                                        | Code        |
| :----------------------------------------------------------- | ----------- |
| [Movie Question Answering: Remembering the Textual Cues for Layered Visual Contents](https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16359) - Bo Wang et al, **AAAI 2018**. | **No code** |

### TIP

| Paper                                                        | Code                                              |
| :----------------------------------------------------------- | ------------------------------------------------- |
| [A Better Way to Attend: Attention With Trees for Video Question Answering](https://ieeexplore.ieee.org/document/8419716) - Hongyang Xue et al, **TIP 2018**. | [[code\]](https://github.com/xuehy/TreeAttention) |



## Before 2018



https://arxiv.org/pdf/1511.04670v1.pdf

| Paper                                                        | Code                                                         |
| :----------------------------------------------------------- | ------------------------------------------------------------ |
| Kuo-Hao Zeng, Tseng-Hung Chen, Ching-Yao Chuang, Yuan-Hong Liao, Juan Carlos Niebles, Min Sun, [**Leveraging Video Descriptions to Learn Video Question Answering**](https://arxiv.org/pdf/1611.04021v2.pdf), AAAI 2017. | **No code**                                                  |
| Makarand Tapaswi, Yukun Zhu, Rainer Stiefelhagen, Antonio Torralba, Raquel Urtasun, Sanja Fidler, **[MovieQA: Understanding Stories in Movies Through Question-Answering](https://openaccess.thecvf.com/content_cvpr_2016/papers/Tapaswi_MovieQA_Understanding_Stories_CVPR_2016_paper.pdf)**, CVPR 2016. | [[code]](https://github.com/makarandtapaswi/MovieQA_benchmark) |
| Linchao Zhu, Zhongwen Xu, Yi Yang, Alexander G. Hauptmann, [**Uncovering Temporal Context for Video Question and Answering**]([1511.04670v1.pdf (arxiv.org)](https://arxiv.org/pdf/1511.04670v1.pdf)), arXiv:1511.05676v1, Nov 2015. | **No code**                                                  |



# Related Tasks

## multi-turn video question answering (video-grounded dialogue)



| Paper                                                        | Code                                                      |
| ------------------------------------------------------------ | --------------------------------------------------------- |
| [DVD: A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue](https://arxiv.org/pdf/2101.00151v2.pdf) - Hung Le et al, **ACL 2021** | [[code]](https://github.com/facebookresearch/DVDialogues) |
| [Structured Co-reference Graph Attention for Video-grounded Dialogue](https://arxiv.org/pdf/2103.13361v1.pdf) - Junyeong Kim et al, **AAAI 2021** | **No code**                                               |
| [Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems](https://aclanthology.org/P19-1564.pdf) - Hung Le et al, **ACL 2019**. | [[code]](https://github.com/henryhungle/MTN)              |



# ....

[MarioQA: Answering Questions by Watching Gameplay Videos](https://ieeexplore.ieee.org/document/8237574) - Jonghwan Mun et al, **ICCV 2017**. **No code** 

**Video Background Music Generation with Controllable Music Transformer** - Shangzhe Di et al, **ACM MM 2021**

